"""
Generate the metadata.csv & waverforms.hdf5 files from PICTS data
A lot of the code has been either taken from or inspired by Szymons notebook
"dataset_test040823.ipynb"; massive help thanks!
"""


import obspy
from obspy import UTCDateTime
from obspy import Stream
from obspy.taup import TauPyModel
from obspy.taup import taup_geo

import pandas as pd
import os

import seisbench.data as sbd
import seisbench.util as sbu


# file containing a catalogue of events
EVENTS_CATALOGUE = "/home/dv1/Documents/Projects_&_Code/2023_QUADRAT/other_data/BGS_Data_N55-59_W01-07_2022-04-01_2023_07_04.csv" #  obtained from BGS Earthquake Database
# constants for seismomenter network
SEIS_NETWORKS = ['9J', 'GB']
SEIS_9J_STATIONS = ['B1BC', 'B3FZ', 'G1WS', 'G2EB', 'G3GB', 'P1GW', 'P2LR', 'P3MM']
SEIS_GB_STATIONS = ['PITL', 'TARL']
SEIS_TRACES = ['HHZ.D', 'HHE.D', 'HHN.D']
# base path for the PICTS data
DATA_BASE_PATH = "/run/media/dv1/T5_D/PICTS/data/PICTS_DATA/2022"
# file containing lon-lat of PICTS stations
STATION_LONLAT_FILE = "/home/dv1/Documents/Projects_&_Code/2023_QUADRAT/other_data/PICTS.lonlat"
# output file paths
METADATA_PATH = "outputs/metadata.csv"
WAVEFORMS_PATH = "outputs/waveforms.hdf5"


def main():
    # load long-lat data for stations
    station_lonlat = load_station_lonlat()
    # load events catalogue
    events = pd.read_csv(EVENTS_CATALOGUE, header=[0])
    # add utcdate column to the events catalogue
    events["utcdate"] = events.apply(lambda row: obspy.UTCDateTime(row["yyyy-mm-dd"] + row["hh:mm:ss.ss"]),
                                          axis="columns")
    # using this model of estimation of p/s arrival times
    model = TauPyModel(model="ak135")
    phase_list = ["P", "S"]

    # write the files
    with sbd.WaveformDataWriter(METADATA_PATH, WAVEFORMS_PATH) as writer:
        writer.data_format = {"dimension_order": "CW",
                              "component_order": "ZNE"}

        for i in range(0, len(events)):
            for net in SEIS_NETWORKS:
                if net == "9J":
                    for station in SEIS_9J_STATIONS:
                        # getting angular distance between event and station
                        dist = taup_geo.calc_dist_azi(events.at[i, "lat"], events.at[i, "lon"],
                                                    station_lonlat[f"{station}.lat"],
                                                    station_lonlat[f"{station}.lon"],
                                                      6371,0)[0]
                        # estimating p/s arrival delay
                        arrivals = model.get_travel_times(source_depth_in_km=events.at[i, "depth"],
                                                          distance_in_degree=dist,
                                                          phase_list=phase_list)
                        # adding p-wave delay to event time to estimate p-wave arrival time
                        utcd = UTCDateTime(events.at[i, "utcdate"])
                        jday = utcd + arrivals[0].time
                        # converting to julian day
                        jday = jday.julday
                        # creating filename in the PICTS data structure from the variables above
                        file = net + "." + station + ".00." + SEIS_TRACES[0] + ".2022." + str(jday)
                        # checking if a file for specific station/day file exists
                        path = os.path.join(DATA_BASE_PATH, net, station, SEIS_TRACES[0], file)
                        check_file = os.path.isfile(path)
                        if check_file:
                            meta = get_meta(i, net, station, events, jday)
                            meta["path_p_travel_s"] = arrivals[0].time
                            # iterating over all channels to add to the wave object
                            wave = Stream()
                            for trace in SEIS_TRACES:
                                file = net + "." + station + ".00." + trace + ".2022." + str(jday)
                                path = os.path.join(DATA_BASE_PATH, net, station, trace, file)
                                wave = wave + obspy.read(path, #reads waveforms 30s before and 30s after p arrival time
                                                starttime = utcd + arrivals[0].time - 30,
                                                endtime = utcd + arrivals[0].time + 30)
                            # writing to the sb data writer
                            if len(wave) != 0:
                                sampling_rate = wave[0].stats.sampling_rate
                                meta["trace_sampling_rate_hz"] = sampling_rate
                                temp1, wave, temp2  = sbu.stream_to_array(wave,
                                                                 component_order=writer.data_format["component_order"])
                                writer.add_trace(meta, wave)
                        # getting julian day for the s-wave arrival and repeating the steps above
                        jday = utcd + arrivals[1].time
                        jday = jday.julday 
                        # creating filename in the PICTS data structure from the variables above
                        file = net + "." + station + ".00." + SEIS_TRACES[0] + ".2022." + str(jday)
                        # checking file for specific station/day file exists
                        path = os.path.join(DATA_BASE_PATH, net, station, SEIS_TRACES[0], file)
                        check_file = os.path.isfile(path)
                        if check_file:
                            meta = get_meta(i, net, station, events, jday)
                            meta["path_s_travel_s"] = arrivals[1].time
                            wave = Stream()
                            for trace in SEIS_TRACES:
                                file = net + "." + station + ".00." + trace + ".2022." + str(jday)
                                path = os.path.join(DATA_BASE_PATH, net, station, trace, file)
                                wave = wave + obspy.read(path,
                                                starttime = utcd + arrivals[1].time - 30,
                                                endtime = utcd + arrivals[1].time + 30)
                            if len(wave) != 0:
                                sampling_rate = wave[0].stats.sampling_rate
                                meta["trace_sampling_rate_hz"] = sampling_rate
                                temp1, wave, temp2 = sbu.stream_to_array(wave,
                                                                 component_order=writer.data_format["component_order"])
                                writer.add_trace(meta, wave)


def get_meta(i, net, stat, events, jday):
    """ Returns a dictionary with the metadata """
    params = {
            "trace_name": net+'.'+stat+'.'+str(events.at[i,'utcdate']),
            "source_id": events.at[i,'locality'],
            "source_origin_time": events.at[i,'utcdate'],
            "source_latitude_deg": events.at[i,'lat'],
            "source_longitude_deg": events.at[i,'lon'],
            "source_depth_km": events.at[i,'depth'],
            "source_magnitude": events.at[i,'ML'],
            "station_network_code": net,
            "station_code": stat,
            "component_order": "ZNE",
            "station_location_code": '00',
            "path_p_travel_s": 0,
            "path_s_travel_s": 0,}

    return(params)


def load_station_lonlat() -> dict[str, float]:
    """ Returns a dictionary with station name.lon & name.lat from file """
    locations: dict[str, float] = dict()
    with open(STATION_LONLAT_FILE) as file:
        for line in file:
            lon, lat, name = line.split()
            locations[f"{name}.lon"] = float(lon)
            locations[f"{name}.lat"] = float(lat)
    return locations


def get_fileswith_extension(*, path: str, ext_match: str) -> list[str]:
    """ Returns a list of file paths for files (located on the path in the argument) that have the specified extension """
    file_list = list()
    for root, dirs, files in os.walk(path):
        for file in files:
            if not file.startswith(".") and file.endswith(ext_match):
                file_list.append(os.path.join(root, file))
    return file_list


if __name__ == "__main__":
    main()